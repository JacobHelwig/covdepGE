---
title: "Fixed sigmasq hyperparameter spec"
output: pdf_document
toc: true
---

```{r, echo = F, include = F, error = T}
start <- Sys.time()

# function for generating the data and the covariates
generate_continuous <- function(n1 = 60, n2 = 60, n3 = 60, p = 4){

  # create covariate for individuals in each of the three intervals
  
  # define the dimensions of the data
  n <- sum(n1, n2, n3)
  
  # define the limits of the intervals
  limits1 <- c(-3, -1)
  limits2 <- c(-1, 1)
  limits3 <- c(1, 3)
  
  # define the covariate values within each interval
  z1 <- runif(n1, limits1[1], limits1[2])
  z2 <- runif(n2, limits2[1], limits2[2])
  z3 <- runif(n3, limits3[1], limits3[2])
  # z1 <- seq(limits1[1], limits1[2], length = n1)
  # z2 <- seq(limits2[1], limits2[2], length = n2)
  # z3 <- seq(limits3[1], limits3[2], length = n3)
  Z <- matrix(sort(c(z1, z2, z3)), n, 1)
  
  # create precision matrices
  
  # the shared part of the structure for all three intervals is a 2 on the
  # diagonal and a 1 in the (2, 3) position
  common_str <- diag(p + 1)
  common_str[2, 3] <- 1
  
  # define constants for the structure of interval 2
  beta1 <- diff(limits2)^-1
  beta0 <- -limits2[1] * beta1
  
  # interval 2 has two different linear functions of Z in the (1, 2) position
  # and (1, 3) positions; define structures for each of these components
  int2_str12 <- int2_str13 <- matrix(0, p + 1, p + 1)
  int2_str12[1, 2] <- int2_str13[1, 3] <- 1
  
  # define the precision matrices for each of the individuals in interval 2
  int2_prec <- lapply(z2, function(z) common_str +
                        ((1 - beta0 - beta1*z)*int2_str12) +
                        ((beta0 + beta1*z)*int2_str13))
  
  # interval 1 has a 1 in the (1, 2) and interval 3 has a 1 in the (1, 3) position;
  # define structures for each of these components
  int1_str12 <- int3_str13 <- matrix(0, p + 1, p + 1)
  int1_str12[1, 2] <- int3_str13[1, 3] <- 1
  
  # define the precision matrices for each of the individuals in interval 1 and interval 3
  int1_prec <- rep(list(common_str + int1_str12), n1)
  int3_prec <- rep(list(common_str + int3_str13), n3)
  
  # put all of the precision matrices into one list
  prec_mats <- c(int1_prec, int2_prec, int3_prec)
  
  # symmetrize the precision matrices
  prec_mats <- lapply(prec_mats, function(mat) t(mat) + mat)
  
  # invert the precision matrices to get the covariance matrices
  cov_mats <- lapply(prec_mats, solve)
  
  # generate the data using the covariance matrices
  data_mat <- t(sapply(cov_mats, MASS::mvrnorm, n = 1, mu = rep(0, p + 1)))
  
  return(list(data = data_mat, covts = Z, true_precision = prec_mats))
}

library(covdepGE)
library(latex2exp)
library(ggpubr)
library(tidyverse)

# colors for plots
set.seed(1)
colors <- c("chartreuse3", "chocolate2", "cornflowerblue", "darkgoldenrod1", 
            "darkmagenta", "deepskyblue3", "forestgreen", "darkorchid3", 
            "darkred", "darkslategray")
colors <- c(colors, sample(colors()[sapply(colors(), function(color) 
  !(substr(color, 1, 4)) %in% c("grey", "gray"))], 180))
```

# Experiment Overview

In this experiment, I compared the results for three methods of hyperparameter selection: `M1`, `M2`, and `M3`. 50 trials were performed.  `M1` proceeded as follows: In each trial, for each variable, $\pi$ was selected by maximizing ELBO over the following grid:

\[\underset\sim\pi = \{0.001, 0.113, 0.226, 0.338, 0.450\}\]

$\sigma^2$ and $\sigma_\beta^2$ were fit to the data for each variable and individual using MAPE.

The optimal $\pi$ was then stabilized in the following manner: upon concluding the first grid search, another grid search was performed using the values of $\mu, \alpha, \sigma^2,$ and $\sigma^2_\beta$ corresponding to the optimal $\pi$ as initial values. If the optimal $\pi$ remained unchanged from the first grid search, then the grid search was concluded. However, if the optimal $\pi$ changed, then the grid search was repeated until the optimal $\pi$ stabilized.

`M2` proceeded exactly as `M1`, except instead of fitting $\sigma^2$ to the data using MAPE, $\sigma^2$ was fixed for all individuals as the sample variance of the variable being treated as the response.

`M3` was a pure grid search in which each of the hyperparameters was optimized by maximizing ELBO over a 3-D grid of 125 points $\sigma^2\times\underset\sim\pi\times\underset\sim{\sigma^2_\beta}$. Since none of the hyperparameters were being fit to the data, the grid search was not iterated until stability as in `M1` and `M2`. $\underset\sim\pi$ was chosen as above, while $\underset\sim{\sigma^2_\beta}$ and $\underset\sim\sigma^2$ were:

\[\underset\sim{\sigma^2_\beta} = \{0.001, 0.005, 0.022, 0.106, 0.5\} \quad\underset\sim\sigma^2 = \{0.2, 0.4, 0.6, 0.8, 1\} \]

The first 30 trials were performed on a relatively small dataset, with $p + 1 = 5$. The last 20 trials were performed on a larger dataset, with $p + 1 = 25$. At the end of each set of trials, the performance of all methods were compared in terms of sensitivity, specificity, accuracy, and time to fit.

Note that I observed the fitted $\sigma^2$ blow up, resulting in erroneous results. This happened most often in the large $p$ case. Thus, if any errors resulted for any of the 3 methods, for example, due to blowup of fitted $\sigma^2$ values, the trial was discarded.

Under each method, the CAVI updates were performed for 100 iterations before exiting, assuming that the tolerance criteria was not met prior to this. 

# Data Generation

## Extraneous Covariate

I generated the covariate, $Z$, as the union of three almost disjoint intervals of equal measure. That is, $Z = Z_1 \cup Z_2 \cup Z_3$ with $Z_1 = (-3, -1), Z_2 = (a,b) = (-1, 1), Z_3 = (1, 3)$. Within each interval, I generated 60 covariate values from a uniform distribution. For example: 

```{r, echo = F, fig.width = 11, fig.height = 4.5, error = T}
cont <- generate_continuous()
X <- cont$data
Z <- cont$covts
n <- nrow(X)
p <- ncol(X) - 1

interval <- c(rep(1, 60), rep(2, 60), rep(3, 60))
cov_df <- cbind.data.frame(interval = interval, Z, individual_index = 1:n)
cov_df$interval <- factor(cov_df$interval)
ggplot(cov_df, aes(Z, fill = interval)) +
  geom_histogram(color = "black", binwidth = 0.2) +
  theme_classic() +
  ggsci::scale_fill_jco() +
  labs(title = ("Distribution of Covariate")) +
  theme(plot.title = element_text(hjust = 0.5))
```

## Precision Matrix

All of the individuals in interval 1 had the same precision matrix, $\Omega^{(1)}$: 

\[\Omega^{(1)}_{i,j} = 
\begin{cases}
2 & i = j \\
1 & (i,j)\in\{(1, 2), (2,1),(2,3),(3,2)\} \\
0 & o.w.
\end{cases}\]

Also, all of the individuals in interval 3 had the same precision matrix, $\Omega^{(3)}$:

\[\Omega^{(3)}_{i,j} = 
\begin{cases}
2 & i = j \\
1 & (i,j)\in\{(1,3), (3,1),(2,3),(3,2)\} \\
0 & o.w.
\end{cases}\]

However, the individuals in interval 2 had a precision matrix that was dependent upon $Z$ and $(a, b)$. Let $\beta_0 = -a / (b - a)$ and $\beta_1 = 1 / (b - a)$. Then:

\[\Omega^{(2)}_{i,j}(z) = 
\begin{cases}
2 & i = j \\
1 & (i,j)\in\{(2,3), (3,2)\} \\
1 - \beta_0 - \beta_1z & (i,j)\in \{(1,2), (2,1)\} \\
\beta_0 + \beta_1z & (i,j)\in\{(1,3),(3,1)\}\\
0 & o.w.
\end{cases}
\]

Thus, $\Omega^{(2)}(a) = \Omega^{(1)}$ and $\Omega^{(2)}(b) = \Omega^{(3)}$. That is, an individual on the left or right boundary of $Z_2$ would have precision matrix $\Omega^{(1)}$ or $\Omega^{(3)}$, respectively. The conditional dependence structures corresponding to each of these precision matrices are visualized below.

```{r, echo = F, fig.width = 11, fig.height = 9, error = T}
# get the true graphs
true_graphs <- lapply(cont$true_precision, function(prec_mat) (prec_mat - diag(diag(prec_mat)) != 0) * 1)

# get the unique true graphs
strs <- unique(true_graphs)

# get the individual indices corresponding to each of the structures
ind_idx <- lapply(strs, function(strc) which(sapply(true_graphs, identical, strc)))

# get the summary for each 
ind_sum <- sapply(ind_idx, function(idx) paste0(min(idx), ",...,", max(idx)))

# visualize each of the structures
str_viz <- lapply(1:length(strs), function(strc_idx) 
  gg_adjMat(strs[[strc_idx]], color1 = colors[strc_idx]) +
    ggtitle(paste("Individuals ", ind_sum[strc_idx])))
ggarrange(plotlist = str_viz)
```

## Data matrix

Let $z_l$ be the extraneous covariate for the $l$-th individual. To generate the data matrix for the $l$-th individual, I took a random sample from $\mathcal N (0,\{\Omega_l(z_l)\}^{-1})$, where: \[\Omega_l(z_l) = 
\begin{cases}
\Omega^{(1)} & z_l\in Z_1 \\
\Omega^{(2)}(z_l) & z_l \in Z_2 \\
\Omega^{(3)} & z_l \in Z_3
\end{cases}
\]


# Results

```{r, echo = F, include = F, error = T}
set.seed(1)

# create the grid of hyperparameters
sigmasq_grid <- seq(0.2, 1, length.out = 5)
sigmabetasq_grid <- exp(seq(log(1e-3), log(0.5), length.out = 5))
pi_grid <- seq(1e-3, 0.45, length.out = 5)
grid <- expand.grid(sigmasq = sigmasq_grid, sigmabeta_sq = sigmabetasq_grid, pi = pi_grid)

# number of trials and number with large p
n_trials <- 50
n_large <- 20



# storage for the results of the j-th trial
results_j <- vector("list", 5)
names(results_j) <- c("covariates", "M1", "M2", "M3", "error")

# storage for all trials
results <- replicate(n_trials, results_j, F)
names(results) <- paste0("trial", 1:n_trials)

# register parallelization
doParallel::registerDoParallel(16)

p <- 4

# perform n_trials trials
for (j in 1:n_trials){
  
  # generate the data
  if (j > n_trials - n_large) p <- 24
  cont <- generate_continuous(p = p)
  X <- cont$data
  Z <- cont$covts
  
  # visualize the covariate
  cov_df <- cbind.data.frame(interval = interval, Z, individual_index = 1:n)
  cov_df$interval <- factor(cov_df$interval)
  cov_plot <- ggplot(cov_df, aes(Z, fill = interval)) +
    geom_histogram(color = "black", binwidth = 0.2) +
    theme_classic() +
    ggsci::scale_fill_jco() +
    labs(title = paste0("Distribution of Covariate, Trial ", j))
  results[[j]]$covariates <- cov_plot
  
  # get the true graphs from the data 
  true_graphs <- lapply(cont$true_precision, function(graph) ((graph - diag(diag(graph))) != 0) * 1)
  
  # total number of 0s and 1s
  tot1 <- sum(unlist(true_graphs) == 1)
  tot0 <- sum(unlist(true_graphs) == 0)
  
  # model using m1
  out <- tryCatch(covdepGE(X, Z, pi_vec = pi_grid, max_iter = 100, parallel = T, 
                           stop_cluster = F, warnings = F), 
                  error = function(error) paste0("m1_error: ", error))
  nll <- is.null(out$model_details$ELBO) | is.na(out$model_details$ELBO) | is.nan(out$model_details$ELBO)
  if (class(out)[1] == "character" | nll){
    results[[j]]$error <- out
    next
  }
  
  # save results of m1
  out_1s <- sum((unlist(out$graphs) + unlist(true_graphs)) == 2)
  out_0s <- sum((unlist(out$graphs) + unlist(true_graphs)) == 0)
  sens <- out_1s / tot1
  spec <- out_0s / tot0
  accu <- (out_1s + out_0s) / (tot1 + tot0)
  results[[j]]$M1 <- list(summary = out, 
                          unique_graphs = plot(out, title_sum = T), 
                          sensitivity = sens, specificity = spec, 
                          accuracy = accu, ELBO = out$model_details$ELBO, 
                          time = as.numeric(out$model_details$elapsed, units = "secs"))
  
  # model using m2
  out <- tryCatch(covdepGE(X, Z, pi_vec = pi_grid, update_sigmasq = F, 
                           max_iter = 100, parallel = T, stop_cluster = F, 
                           warnings = F), 
                  error = function(error) paste0("m2_error: ", error))
  nll <- is.null(out$model_details$ELBO) | is.na(out$model_details$ELBO) | is.nan(out$model_details$ELBO)
  if (class(out)[1] == "character" | nll){
    results[[j]]$error <- out
    next
  }
  
  # save results of m2
  out_1s <- sum((unlist(out$graphs) + unlist(true_graphs)) == 2)
  out_0s <- sum((unlist(out$graphs) + unlist(true_graphs)) == 0)
  sens <- out_1s / tot1
  spec <- out_0s / tot0
  accu <- (out_1s + out_0s) / (tot1 + tot0)
  results[[j]]$M2 <- list(summary = out, 
                          unique_graphs = plot(out, title_sum = T), 
                          sensitivity = sens, specificity = spec, 
                          accuracy = accu, ELBO = out$model_details$ELBO, 
                          time = as.numeric(out$model_details$elapsed, units = "secs"))
  
  # model using m3
  out <- tryCatch(covdepGE(X, Z, pi_vec = grid$pi, sigmasq_vec = grid$sigmasq,
                          sigmabetasq_vec = grid$sigmabeta_sq, max_iter = 100, 
                          parallel = T, stop_cluster = F, warnings = F), 
                  error = function(error) paste0("m3_error: ", error))
  nll <- is.null(out$model_details$ELBO) | is.na(out$model_details$ELBO) | is.nan(out$model_details$ELBO)
  if (class(out)[1] == "character" | nll){
    results[[j]]$error <- out
    next
  }
  
  # save results of m3
  out_1s <- sum((unlist(out$graphs) + unlist(true_graphs)) == 2)
  out_0s <- sum((unlist(out$graphs) + unlist(true_graphs)) == 0)
  sens <- out_1s / tot1
  spec <- out_0s / tot0
  accu <- (out_1s + out_0s) / (tot1 + tot0)
  results[[j]]$M3 <- list(summary = out,
                          unique_graphs = plot(out, title_sum = T), 
                          sensitivity = sens, specificity = spec, 
                          accuracy = accu, ELBO = out$model_details$ELBO, 
                          time = as.numeric(out$model_details$elapsed, units = "secs"))


}
doParallel::stopImplicitCluster()
```

```{r, fig.width = 11, fig.height = 6, echo = F, error = T}
# gather all of the metrics of interest for each method

# m1 metrics
m1_res <- lapply(results, `[[`, "M1")
m1_sens <- sapply(m1_res, `[[`, "sensitivity")
m1_spec <- sapply(m1_res, `[[`, "specificity")
m1_acc <- sapply(m1_res, `[[`, "accuracy")
m1_ELBO <- sapply(m1_res, `[[`, "ELBO")
m1_time <- sapply(m1_res, `[[`, "time")

# divide m1 metrics into p = 5 and p = 25
m1_sens5 <- m1_sens[1:(n_trials - n_large)]
m1_sens25 <- m1_sens[(n_trials - n_large + 1):n_trials]
m1_spec5 <- m1_spec[1:(n_trials - n_large)]
m1_spec25 <- m1_spec[(n_trials - n_large + 1):n_trials]
m1_acc5 <- m1_acc[1:(n_trials - n_large)]
m1_acc25 <- m1_acc[(n_trials - n_large + 1):n_trials]
m1_ELBO5 <- m1_ELBO[1:(n_trials - n_large)]
m1_ELBO25 <- m1_ELBO[(n_trials - n_large + 1):n_trials]
m1_time5 <- m1_time[1:(n_trials - n_large)]
m1_time25 <- m1_time[(n_trials - n_large + 1):n_trials]

# m2 metrics
m2_res <- lapply(results, `[[`, "M2")
m2_sens <- sapply(m2_res, `[[`, "sensitivity")
m2_spec <- sapply(m2_res, `[[`, "specificity")
m2_acc <- sapply(m2_res, `[[`, "accuracy")
m2_ELBO <- sapply(m2_res, `[[`, "ELBO")
m2_time <- sapply(m2_res, `[[`, "time")

# divide m2 metrics into p = 5 and p = 25
m2_sens5 <- m2_sens[1:(n_trials - n_large)]
m2_sens25 <- m2_sens[(n_trials - n_large + 1):n_trials]
m2_spec5 <- m2_spec[1:(n_trials - n_large)]
m2_spec25 <- m2_spec[(n_trials - n_large + 1):n_trials]
m2_acc5 <- m2_acc[1:(n_trials - n_large)]
m2_acc25 <- m2_acc[(n_trials - n_large + 1):n_trials]
m2_ELBO5 <- m2_ELBO[1:(n_trials - n_large)]
m2_ELBO25 <- m2_ELBO[(n_trials - n_large + 1):n_trials]
m2_time5 <- m2_time[1:(n_trials - n_large)]
m2_time25 <- m2_time[(n_trials - n_large + 1):n_trials]

# m3 metrics
m3_res <- lapply(results, `[[`, "M3")
m3_sens <- sapply(m3_res, `[[`, "sensitivity")
m3_spec <- sapply(m3_res, `[[`, "specificity")
m3_acc <- sapply(m3_res, `[[`, "accuracy")
m3_ELBO <- sapply(m3_res, `[[`, "ELBO")
m3_time <- sapply(m3_res, `[[`, "time")

# divide m3 metrics into p = 5 and p = 25
m3_sens5 <- m3_sens[1:(n_trials - n_large)]
m3_sens25 <- m3_sens[(n_trials - n_large + 1):n_trials]
m3_spec5 <- m3_spec[1:(n_trials - n_large)]
m3_spec25 <- m3_spec[(n_trials - n_large + 1):n_trials]
m3_acc5 <- m3_acc[1:(n_trials - n_large)]
m3_acc25 <- m3_acc[(n_trials - n_large + 1):n_trials]
m3_ELBO5 <- m3_ELBO[1:(n_trials - n_large)]
m3_ELBO25 <- m3_ELBO[(n_trials - n_large + 1):n_trials]
m3_time5 <- m3_time[1:(n_trials - n_large)]
m3_time25 <- m3_time[(n_trials - n_large + 1):n_trials]
```
```{r, fig.width = 11, fig.height = 6, error = T}
n <- 180
n_3 <- n^(-1/3)

# sensitivity comparison (5)

# m1 - m2
data.frame(X = m1_sens5 - m2_sens5) %>% ggplot(aes(X)) +
  ggtitle(TeX("Sensitivity, p = 5: $M_1 - M_2$")) +
  xlab("Sensitivity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_sens5 - m2_sens5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_sens5 - m2_sens5)

# m1 - m3
data.frame(X = m1_sens5 - m3_sens5) %>% ggplot(aes(X)) +
  ggtitle(TeX("Sensitivity, p = 5: $M_1 - M_3$")) +
  xlab("Sensitivity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_sens5 - m3_sens5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_sens5 - m3_sens5)

# m2 - m3
data.frame(X = m2_sens5 - m3_sens5) %>% ggplot(aes(X)) +
  ggtitle(TeX("Sensitivity, p = 5: $M_2 - M_3$")) +
  xlab("Sensitivity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m2_sens5 - m3_sens5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m2_sens5 - m3_sens5)

# sensitivity comparison (25)

# m1 - m2
data.frame(X = m1_sens25 - m2_sens25) %>% ggplot(aes(X)) +
  ggtitle(TeX("Sensitivity, p = 25: $M_1 - M_2$")) +
  xlab("Sensitivity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_sens25 - m2_sens25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_sens25 - m2_sens25)

# m1 - m3
data.frame(X = m1_sens25 - m3_sens25) %>% ggplot(aes(X)) +
  ggtitle(TeX("Sensitivity, p = 25: $M_1 - M_3$")) +
  xlab("Sensitivity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_sens25 - m3_sens25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_sens25 - m3_sens25)

# m2 - m3
data.frame(X = m2_sens25 - m3_sens25) %>% ggplot(aes(X)) +
  ggtitle(TeX("Sensitivity, p = 25: $M_2 - M_3$")) +
  xlab("Sensitivity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m2_sens25 - m3_sens25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m2_sens25 - m3_sens25)

# specificity comparison (5)

# m1 - m2
data.frame(X = m1_spec5 - m2_spec5) %>% ggplot(aes(X)) +
  ggtitle(TeX("Specificity, p = 5: $M_1 - M_2$")) +
  xlab("Specificity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_spec5 - m2_spec5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_spec5 - m2_spec5)

# m1 - m3
data.frame(X = m1_spec5 - m3_spec5) %>% ggplot(aes(X)) +
  ggtitle(TeX("Specificity, p = 5: $M_1 - M_3$")) +
  xlab("Specificity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_spec5 - m3_spec5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_spec5 - m3_spec5)

# m2 - m3
data.frame(X = m2_spec5 - m3_spec5) %>% ggplot(aes(X)) +
  ggtitle(TeX("Specificity, p = 5: $M_2 - M_3$")) +
  xlab("Specificity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m2_spec5 - m3_spec5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m2_spec5 - m3_spec5)

# specificity comparison (25)

# m1 - m2
data.frame(X = m1_spec25 - m2_spec25) %>% ggplot(aes(X)) +
  ggtitle(TeX("Specificity, p = 25: $M_1 - M_2$")) +
  xlab("Specificity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_spec25 - m2_spec25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_spec25 - m2_spec25)

# m1 - m3
data.frame(X = m1_spec25 - m3_spec25) %>% ggplot(aes(X)) +
  ggtitle(TeX("Specificity, p = 25: $M_1 - M_3$")) +
  xlab("Specificity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m1_spec25 - m3_spec25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_spec25 - m3_spec25)

# m2 - m3
data.frame(X = m2_spec25 - m3_spec25) %>% ggplot(aes(X)) +
  ggtitle(TeX("Specificity, p = 25: $M_2 - M_3$")) +
  xlab("Specificity Difference") + 
  geom_histogram(binwidth = 2 * IQR(m2_spec25 - m3_spec25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m2_spec25 - m3_spec25)

# distribution of ELBO

# p = 5

# m1
data.frame(X = m1_ELBO5) %>% ggplot(aes(X)) + 
  ggtitle(TeX("ELBO, p = 5: $M_1$")) + 
  xlab("ELBO") + 
  geom_histogram(binwidth = 2 * IQR(m1_ELBO5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_ELBO5)

# m2
data.frame(X = m2_ELBO5) %>% ggplot(aes(X)) + 
  ggtitle(TeX("ELBO, p = 5: $M_2$")) + 
  xlab("ELBO") + 
  geom_histogram(binwidth = 2 * IQR(m2_ELBO5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m2_ELBO5)

# m3
data.frame(X = m3_ELBO5) %>% ggplot(aes(X)) + 
  ggtitle(TeX("ELBO, p = 5: $M_3$")) + 
  xlab("ELBO") + 
  geom_histogram(binwidth = 2 * IQR(m3_ELBO5) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m3_ELBO5)

# p = 25

# m1
data.frame(X = m1_ELBO25) %>% ggplot(aes(X)) + 
  ggtitle(TeX("ELBO, p = 25: $M_1$")) + 
  xlab("ELBO") + 
  geom_histogram(binwidth = 2 * IQR(m1_ELBO25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m1_ELBO25)

# m2
data.frame(X = m2_ELBO25) %>% ggplot(aes(X)) + 
  ggtitle(TeX("ELBO, p = 25: $M_2$")) + 
  xlab("ELBO") + 
  geom_histogram(binwidth = 2 * IQR(m2_ELBO25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m2_ELBO25)

# m3
data.frame(X = m3_ELBO25) %>% ggplot(aes(X)) + 
  ggtitle(TeX("ELBO, p = 25: $M_3$")) + 
  xlab("ELBO") + 
  geom_histogram(binwidth = 2 * IQR(m3_ELBO25) * n_3, color = "black") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
summary(m3_ELBO25)
```



```{r, fig.width = 4.5, fig.height = 3.5, error = T}
Sys.time() - start

# find errors
errs <- sapply(results, `[[`, "error")
err_log <- !sapply(errs, is.null)
errs[err_log]

# display a single non-large example
results[!err_log][1]

# display a single large example
results[!err_log & 1:n_trials > (n_trials - n_large)][1]
```
