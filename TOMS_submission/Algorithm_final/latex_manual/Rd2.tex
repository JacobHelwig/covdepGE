


% this was generated by running R CMD Rd2pdf . --no-clean (https://stackoverflow.com/questions/63360467/get-single-latex-file-instead-of-pdf-for-documentation-of-r-package)

% Rd.sty is from C:\Program Files\R\R-4.2.1\share\texmf\tex\latex




% this was generated by running R CMD Rd2pdf . --no-clean (https://stackoverflow.com/questions/63360467/get-single-latex-file-instead-of-pdf-for-documentation-of-r-package)

% Rd.sty is from C:\Program Files\R\R-4.2.1\share\texmf\tex\latex

\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8]{inputenc} % @SET ENCODING@
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `covdepGE'}}
\par\bigskip{\large \today}
\end{center}
\inputencoding{utf8}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {covdepGE: Covariate Dependent Graph Estimation}}}{}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdfauthor = {Jacob Helwig; Sutanoy Dasgupta; Peng Zhao; Bani Mallick; Debdeep Pati}}}{}
\begin{description}
\raggedright{}
\item[Title]\AsIs{Covariate Dependent Graph Estimation}
\item[Version]\AsIs{1.0.1}
\item[Date]\AsIs{2022-09-16}
\item[Language]\AsIs{en-US}
\item[BugReports]\AsIs{}\url{https://github.com/JacobHelwig/covdepGE/issues}\AsIs{}
\item[URL]\AsIs{}\url{https://github.com/JacobHelwig/covdepGE}\AsIs{}
\item[Description]\AsIs{A covariate-dependent approach to Gaussian graphical modeling as described in Dasgupta et al. (2022). Employs a novel weighted pseudo-likelihood approach to model the conditional dependence structure of data as a continuous function of an extraneous covariate. The main function, covdepGE::covdepGE(), estimates a graphical representation of the conditional dependence structure via a block mean-field variational approximation, while several auxiliary functions (inclusionCurve(), matViz(), and plot.covdepGE()) are included for visualizing the resulting estimates. }
\item[License]\AsIs{GPL (>= 3)}
\item[Encoding]\AsIs{UTF-8}
\item[LazyData]\AsIs{true}
\item[Roxygen]\AsIs{list(markdown = TRUE)}
\item[RoxygenNote]\AsIs{7.2.3}
\item[LinkingTo]\AsIs{Rcpp,
RcppArmadillo}
\item[Imports]\AsIs{doParallel,
foreach,
ggplot2,
glmnet,
latex2exp,
MASS,
parallel,
Rcpp,
reshape2,
stats}
\item[Suggests]\AsIs{testthat (>= 3.0.0),
covr,
vdiffr}
\item[Config/testthat/edition]\AsIs{3}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{covdepGE-package}{covdepGE: Covariate Dependent Graph Estimation}{covdepGE.Rdash.package}
\aliasA{\_PACKAGE}{covdepGE-package}{.Rul.PACKAGE}
%
\begin{Description}\relax
A covariate-dependent approach to Gaussian graphical modeling as described in Dasgupta et al. (2022). Employs a novel weighted pseudo-likelihood approach to model the conditional dependence structure of data as a continuous function of an extraneous covariate. The main function, covdepGE::covdepGE(), estimates a graphical representation of the conditional dependence structure via a block mean-field variational approximation, while several auxiliary functions (inclusionCurve(), matViz(), and plot.covdepGE()) are included for visualizing the resulting estimates.
\end{Description}
%
\begin{Author}\relax
\strong{Maintainer}: Jacob Helwig \email{jacob.a.helwig@tamu.edu}

Authors:
\begin{itemize}

\item{} Sutanoy Dasgupta \email{sutanoy@stat.tamu.edu}
\item{} Peng Zhao \email{pzhao@udel.edu}
\item{} Bani Mallick \email{bmallick@stat.tamu.edu}
\item{} Debdeep Pati \email{debdeep@stat.tamu.edu}

\end{itemize}


\end{Author}
%
\begin{References}\relax
(1) Sutanoy Dasgupta, Peng Zhao, Jacob Helwig, Prasenjit Ghosh, Debdeep Pati,
and Bani Mallick. An Approximate Bayesian Approach to Covariate-dependent
Graphical Modeling. \emph{arXiv preprint}, 1â€“64, 2023.
\end{References}
%
\begin{SeeAlso}\relax
Useful links:
\begin{itemize}

\item{} \url{https://github.com/JacobHelwig/covdepGE}
\item{} Report bugs at \url{https://github.com/JacobHelwig/covdepGE/issues}

\end{itemize}


\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{covdepGE}{Covariate Dependent Graph Estimation}{covdepGE}
\aliasA{covdepGE-method}{covdepGE}{covdepGE.Rdash.method}
%
\begin{Description}\relax
Model the conditional dependence structure of \code{X} as a function
of \code{Z} as described in (1)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
covdepGE(
  X,
  Z = NULL,
  hp_method = "hybrid",
  ssq = NULL,
  sbsq = NULL,
  pip = NULL,
  nssq = 5,
  nsbsq = 5,
  npip = 5,
  ssq_mult = 1.5,
  ssq_lower = 1e-05,
  snr_upper = 25,
  sbsq_lower = 1e-05,
  pip_lower = 1e-05,
  pip_upper = NULL,
  tau = NULL,
  norm = 2,
  center_X = TRUE,
  scale_Z = TRUE,
  alpha_tol = 1e-05,
  max_iter_grid = 10,
  max_iter = 100,
  edge_threshold = 0.5,
  sym_method = "mean",
  parallel = FALSE,
  num_workers = NULL,
  prog_bar = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X}] \eqn{n \times p}{} numeric matrix; data matrix. For best
results, \eqn{n}{} should be greater than \eqn{p}{}

\item[\code{Z}] \code{NULL} OR \eqn{n \times q}{} numeric matrix; extraneous
covariates. If \code{NULL}, \code{Z} will be treated as constant for all observations,
i.e.:

\begin{alltt}Z <- rep(0, nrow(X))
\end{alltt}


If \code{Z} is constant, the estimated graph will be homogeneous throughout the
data. \code{NULL} by default

\item[\code{hp\_method}] \code{character} in \code{c("grid\_search","model\_average","hybrid")};
method for selecting hyperparameters from the the hyperparameter grid. The
grid will be generated as the Cartesian product of \code{ssq}, \code{sbsq}, and \code{pip}.
Fix \eqn{X_j}{}, the \eqn{j}{}-th column of \code{X}, as the response; then, the
hyperparameters will be selected as follows:

\begin{itemize}

\item{} If \code{"grid\_search"}, the point in the hyperparameter grid that
maximizes the total ELBO summed across all \eqn{n}{} regressions will be
selected
\item{} If \code{"model\_average"}, then all posterior quantities will be an
average of the variational estimates resulting from the model fit for each
point in the hyperparameter grid. The unnormalized averaging weights for
each of the \eqn{n}{} regressions are the exponentiated ELBO
\item{} If \code{"hybrid"}, then models will be averaged over \code{pip} as in
\code{"model\_average"}, with \eqn{\sigma^2}{} and
\eqn{\sigma_\beta^2}{} chosen for each \eqn{\pi}{} in \code{pip}
by maximizing the total ELBO over the grid defined by the Cartesian
product of \code{ssq} and \code{sbsq} as in \code{"grid\_search"}

\end{itemize}


\code{"hybrid"} by default

\item[\code{ssq}] \code{NULL} OR numeric vector with positive entries; candidate values
of the hyperparameter \eqn{\sigma^2}{} (prior residual variance). If
\code{NULL}, \code{ssq} will be generated for each variable \eqn{X_j}{} fixed as the
response as:

\begin{alltt}ssq <- seq(ssq_lower, ssq_upper, length.out = nssq)
\end{alltt}


\code{NULL} by default

\item[\code{sbsq}] \code{NULL} OR numeric vector with positive entries; candidate values
of the hyperparameter \eqn{\sigma_\beta^2}{} (prior slab
variance). If \code{NULL}, \code{sbsq} will be generated for each variable
\eqn{X_j}{} fixed as the response as:

\begin{alltt}sbsq <- seq(sbsq_lower, sbsq_upper, length.out = nsbsq)
\end{alltt}


\code{NULL} by default

\item[\code{pip}] \code{NULL} OR numeric vector with entries in \eqn{(0, 1)}{}; candidate
values of the hyperparameter \eqn{\pi}{} (prior inclusion probability). If
\code{NULL}, \code{pip} will be generated for each variable \eqn{X_j}{} fixed as the
response as:

\begin{alltt}pip <- seq(pip_lower, pi_upper, length.out = npip)
\end{alltt}


\code{NULL} by default

\item[\code{nssq}] positive integer; number of points to generate for \code{ssq} if
\code{ssq} is \code{NULL}. \code{5} by default

\item[\code{nsbsq}] positive integer; number of points to generate for \code{sbsq} if
\code{sbsq} is \code{NULL}. \code{5} by default

\item[\code{npip}] positive integer; number of points to generate for \code{pip} if \code{pip}
is \code{NULL}. \code{5} by default

\item[\code{ssq\_mult}] positive numeric; if \code{ssq} is \code{NULL}, then for each variable
\eqn{X_j}{} fixed as the response:

\begin{alltt}ssq_upper <- ssq_mult * stats::var(X_j)
\end{alltt}


Then, \code{ssq\_upper} will be the greatest value in \code{ssq} for variable
\eqn{X_j}{}. \code{1.5} by default

\item[\code{ssq\_lower}] positive numeric; if \code{ssq} is \code{NULL}, then \code{ssq\_lower} will
be the least value in \code{ssq}. \code{1e-5} by default

\item[\code{snr\_upper}] positive numeric; upper bound on the signal-to-noise ratio.
If \code{sbsq} is \code{NULL}, then for each variable \eqn{X_j}{} fixed as the
response:

\begin{alltt}s2_sum <- sum(apply(X, 2, stats::var))
sbsq_upper <- snr_upper / (pip_upper * s2_sum)
\end{alltt}


Then, \code{sbsq\_upper} will be the greatest value in \code{sbsq}. \code{25} by default

\item[\code{sbsq\_lower}] positive numeric; if \code{sbsq} is \code{NULL}, then \code{sbsq\_lower}
will be the least value in \code{sbsq}. \code{1e-5} by default

\item[\code{pip\_lower}] numeric in \eqn{(0, 1)}{}; if \code{pip} is \code{NULL}, then
\code{pip\_lower} will be the least value in \code{pip}. \code{1e-5} by default

\item[\code{pip\_upper}] \code{NULL} OR  numeric in \eqn{(0, 1)}{}; if \code{pip} is \code{NULL}, then
\code{pip\_upper} will be the greatest value in \code{pip}. If \code{sbsq} is \code{NULL},
\code{pip\_upper} will be used to calculate \code{sbsq\_upper}. If \code{NULL}, \code{pip\_upper}
will be calculated for each variable \eqn{X_j}{} fixed as the response as:

\begin{alltt}lasso <- glmnet::cv.glmnet(X, X_j)
non0 <- sum(glmnet::coef.glmnet(lasso, s = "lambda.1se")[-1] != 0)
non0 <- min(max(non0, 1), p - 1)
pip_upper <- non0 / p
\end{alltt}


\code{NULL} by default

\item[\code{tau}] \code{NULL} OR positive numeric OR numeric vector of length \eqn{n}{}
with positive entries; bandwidth parameter. Greater values allow for more
information to be shared between observations. Allows for global or
observation-specific specification. If \code{NULL}, use 2-step KDE methodology as
described in (2) to calculate observation-specific bandwidths. \code{NULL} by
default

\item[\code{norm}] numeric in \eqn{[1, \infty]}{}; norm to use when
calculating weights. \code{Inf} results in infinity norm. \code{2} by default

\item[\code{center\_X}] logical; if \code{TRUE}, center \code{X} column-wise to mean \eqn{0}{}.
\code{TRUE} by default

\item[\code{scale\_Z}] logical; if \code{TRUE}, center and scale \code{Z} column-wise to mean
\eqn{0}{}, standard deviation \eqn{1}{} prior to calculating the weights. \code{TRUE}
by default

\item[\code{alpha\_tol}] positive numeric; end CAVI when the Frobenius norm of the
change in the alpha matrix is within \code{alpha\_tol}. \code{1e-5} by default

\item[\code{max\_iter\_grid}] positive integer; if tolerance criteria has not been
met by \code{max\_iter\_grid} iterations during grid search, end CAVI. After grid
search has completed, CAVI is performed with the final hyperparameters
selected by grid search for at most \code{max\_iter} iterations. Does not apply to
\code{hp\_method = "model\_average"}. \code{10} by default

\item[\code{max\_iter}] positive integer; if tolerance criteria has not been met by
\code{max\_iter} iterations, end CAVI. \code{100} by default

\item[\code{edge\_threshold}] numeric in \eqn{(0, 1)}{}; a graph for each observation
will be constructed by including an edge between variable \eqn{i}{} and
variable \eqn{j}{} if, and only if, the \eqn{(i, j)}{} entry of the symmetrized
posterior inclusion probability matrix corresponding to the observation is
greater than \code{edge\_threshold}. \code{0.5} by default

\item[\code{sym\_method}] \code{character} in \code{c("mean","max","min")}; to symmetrize
the posterior inclusion probability matrix for each observation, the
\eqn{(i, j)}{} and \eqn{(j, i)}{} entries will be post-processed as \code{sym\_method}
applied to the \eqn{(i, j)}{} and \eqn{(j, i)}{} entries. \code{"mean"} by default

\item[\code{parallel}] logical; if \code{TRUE}, hyperparameter selection and CAVI for
each of the \eqn{p}{} variables will be performed in parallel using \code{foreach}.
Parallel backend may be registered prior to making a call to \code{covdepGE}. If
no active parallel backend can be detected, then parallel backend will be
automatically registered using:

\begin{alltt}doParallel::registerDoParallel(num_workers)
\end{alltt}


\code{FALSE} by default

\item[\code{num\_workers}] \code{NULL} OR positive integer less than or equal to
\code{parallel::detectCores()}; argument to \code{doParallel::registerDoParallel} if
\code{parallel = TRUE} and no parallel backend is detected. If \code{NULL}, then:

\begin{alltt}num_workers <- floor(parallel::detectCores() / 2)
\end{alltt}


\code{NULL} by default

\item[\code{prog\_bar}] logical; if \code{TRUE}, then a progress bar will be displayed
denoting the number of remaining variables to fix as the response and perform
CAVI. If \code{parallel}, no progress bar will be displayed. \code{TRUE} by default
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns object of class \code{covdepGE} with the following values:

\begin{ldescription}
\item[\code{graphs}] list with the following values:

\begin{itemize}

\item{} \code{graphs}: list of \eqn{n}{} numeric matrices of dimension
\eqn{p \times p}{}; the \eqn{l}{}-th matrix is the adjacency matrix
for the \eqn{l}{}-th observation
\item{} \code{unique\_graphs}: list; the \eqn{l}{}-th element is a list containing
the \eqn{l}{}-th unique graph and the indices of the observation(s)
corresponding to this graph
\item{} \code{inclusion\_probs\_sym}: list of \eqn{n}{} numeric matrices of
dimension \eqn{p \times p}{}; the \eqn{l}{}-th matrix is the
symmetrized posterior inclusion probability matrix for the \eqn{l}{}-th
observation
\item{} \code{inclusion\_probs\_asym}: list of \eqn{n}{} numeric matrices of
dimension \eqn{p \times p}{}; the \eqn{l}{}-th matrix is the
posterior inclusion probability matrix for the \eqn{l}{}-th observation
prior to symmetrization

\end{itemize}



\item[\code{variational\_params}] list with the following values:

\begin{itemize}

\item{} \code{alpha}: list of \eqn{p}{} numeric matrices of dimension
\eqn{n \times (p - 1)}{}; the \eqn{(i, j)}{} entry of the
\eqn{k}{}-th matrix is the variational approximation to the posterior
inclusion probability of the \eqn{j}{}-th variable in a weighted
regression with variable \eqn{k}{} fixed as the response, where the
weights are taken with respect to observation \eqn{i}{}
\item{} \code{mu}: list of \eqn{p}{} numeric matrices of dimension
\eqn{n \times (p - 1)}{}; the \eqn{(i, j)}{} entry of the
\eqn{k}{}-th matrix is the variational approximation to the posterior slab
mean for the \eqn{j}{}-th variable in a weighted regression with variable
\eqn{k}{} fixed as the response, where the weights are taken with respect
to observation \eqn{i}{}
\item{} \code{ssq\_var}: list of \eqn{p}{} numeric
matrices of dimension \eqn{n \times (p - 1)}{}; the
\eqn{(i, j)}{} entry of the \eqn{k}{}-th matrix is the variational
approximation to the posterior slab variance for the \eqn{j}{}-th variable
in a weighted regression with variable \eqn{k}{} fixed as the response,
where the weights are taken with respect to observation \eqn{i}{}

\end{itemize}



\item[\code{hyperparameters}] list of \eqn{p}{} lists; the \eqn{j}{}-th list has the
following values for variable \eqn{j}{} fixed as the response:

\begin{itemize}

\item{} \code{grid}: matrix of candidate hyperparameter values, corresponding
ELBO, and iterations to converge
\item{} \code{final}: the final hyperparameters chosen by grid search and the
ELBO and iterations to converge for these hyperparameters

\end{itemize}



\item[\code{model\_details}] list with the following values:

\begin{itemize}

\item{} \code{elapsed}: amount of time to fit the model
\item{} \code{n}: number of observations
\item{} \code{p}: number of variables
\item{} \code{ELBO}: ELBO summed across all observations and variables. If
\code{hp\_method} is \code{"model\_average"} or \code{"hybrid"}, this ELBO is averaged
across the hyperparameter grid using the model averaging weights for
each variable
\item{} \code{num\_unique}: number of unique graphs
\item{} \code{grid\_size}: number of points in the hyperparameter grid
\item{} \code{args}: list containing all passed arguments of length \eqn{1}{}

\end{itemize}



\item[\code{weights}] list with the following values:

\begin{itemize}

\item{} \code{weights}: \eqn{n\times n}{} numeric matrix. The \eqn{(i, j)}{}
entry is the similarity weight of the \eqn{i}{}-th observation with
respect to the \eqn{j}{}-th observation using the \eqn{j}{}-th observation's
bandwidth
\item{} \code{bandwidths}: numeric vector of length \eqn{n}{}. The \eqn{i}{}-th
entry is the bandwidth for the \eqn{i}{}-th observation

\end{itemize}


\end{ldescription}
\end{Value}
%
\begin{References}\relax
(1) Sutanoy Dasgupta, Peng Zhao, Jacob Helwig, Prasenjit Ghosh, Debdeep Pati,
and Bani Mallick. An Approximate Bayesian Approach to Covariate-dependent
Graphical Modeling. \emph{arXiv preprint}, 1â€“64, 2023.

(2) Sutanoy Dasgupta, Debdeep Pati, and Anuj Srivastava. A Two-Step Geometric
Framework For Density Modeling. \emph{Statistica Sinica}, 30(4):2155â€“2177, 2020.
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
library(ggplot2)

# get the data
set.seed(12)
data <- generateData()
X <- data$X
Z <- data$Z
interval <- data$interval
prec <- data$true_precision

# get overall and within interval sample sizes
n <- nrow(X)
n1 <- sum(interval == 1)
n2 <- sum(interval == 2)
n3 <- sum(interval == 3)

# visualize the distribution of the extraneous covariate
ggplot(data.frame(Z = Z, interval = as.factor(interval))) +
  geom_histogram(aes(Z, fill = interval), color = "black", bins = n %/% 5)

# visualize the true precision matrices in each of the intervals

# interval 1
matViz(prec[[1]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 1, observations 1,...,", n1))

# interval 2 (varies continuously with Z)
cat("\nInterval 2, observations ", n1 + 1, ",...,", n1 + n2, sep = "")
int2_mats <- prec[interval == 2]
int2_inds <- c(5, n2 %/% 2, n2 - 5)
lapply(int2_inds, function(j) matViz(int2_mats[[j]], incl_val = TRUE) +
         ggtitle(paste("True precision matrix, interval 2, observation", j + n1)))

# interval 3
matViz(prec[[length(prec)]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 3, observations ",
                 n1 + n2 + 1, ",...,", n1 + n2 + n3))

# fit the model and visualize the estimated graphs
(out <- covdepGE(X, Z))
plot(out)

# visualize the posterior inclusion probabilities for variables (1, 3) and (1, 2)
inclusionCurve(out, 1, 2)
inclusionCurve(out, 1, 3)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{generateData}{Generate Covariate-Dependent Data}{generateData}
%
\begin{Description}\relax
Generate a \eqn{1}{}-dimensional extraneous covariate
and \eqn{p}{}-dimensional Gaussian data with a precision matrix that varies as
a continuous function of the extraneous covariate. This data is distributed
similar to that used in the simulation study from (1)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
generateData(p = 5, n1 = 60, n2 = 60, n3 = 60, Z = NULL, true_precision = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{p}] positive integer; number of variables in the data matrix. \code{5} by
default

\item[\code{n1}] positive integer; number of observations in the first interval.
\code{60} by default

\item[\code{n2}] positive integer; number of observations in the second interval.
\code{60} by default

\item[\code{n3}] positive integer; number of observations in the third interval.
\code{60} by default

\item[\code{Z}] \code{NULL} or numeric vector; extraneous covariate values for each
observation. If \code{NULL}, \code{Z} will be generated from a uniform distribution on
each of the intervals

\item[\code{true\_precision}] \code{NULL} OR list of matrices of dimension
\eqn{p \times p}{}; true precision matrix for each observation. If
\code{NULL}, the true precision matrices will be generated dependent on \code{Z}.
\code{NULL} by default
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns list with the following values:

\begin{ldescription}
\item[\code{X}] a \code{(n1 + n2 + n3)} \eqn{\times p}{} numeric matrix, where
the \eqn{i}{}-th row is drawn from a \eqn{p}{}-dimensional Gaussian with mean
\eqn{0}{} and precision matrix \code{true\_precision[[i]]}

\item[\code{Z}] a \code{(n1 + n2 + n3)} \eqn{\times 1}{} numeric matrix, where
the \eqn{i}{}-th entry is the extraneous covariate \eqn{z_i}{} for
observation \eqn{i}{}

\item[\code{true\_precision}] list of \code{n1 + n2 + n3} matrices of dimension
\eqn{p \times p}{}; the \eqn{i}{}-th matrix is the precision matrix for
the \eqn{i}{}-th observation

\item[\code{interval}] vector of length \code{n1 + n2 + n3}; interval assignments
for each of the observations, where the \eqn{i}{}-th entry is the interval
assignment for the \eqn{i}{}-th observation
\end{ldescription}
\end{Value}
%
\begin{Section}{Extraneous Covariate}
If \code{Z = NULL}, then the generation of \code{Z} is as follows:

The first \code{n1} observations have \eqn{z_i}{} from from a uniform
distribution on the interval \eqn{(-3, -1)}{} (the first interval).

Observations \code{n1 + 1} to \code{n1 + n2} have \eqn{z_i}{} from from a uniform
distribution on the interval \eqn{(-1, 1)}{} (the second interval).

Observations \code{n1 + n2 + 1} to \code{n1 + n2 + n3} have \eqn{z_i}{} from a
uniform distribution on the interval \eqn{(1, 3)}{} (the third interval).
\end{Section}
%
\begin{Section}{Precision Matrices}
If \code{true\_precision = NULL}, then the generation of the true precision
matrices is as follows:

All precision matrices have \eqn{2}{} on the diagonal and \eqn{1}{} in the
\eqn{(2, 3)/ (3, 2)}{} positions.

Observations in the first interval have a \eqn{1}{} in the
\eqn{(1, 2) / (1, 2)}{} positions, while observations in the third interval
have a \eqn{1}{} in the \eqn{(1, 3)/ (3, 1)}{} positions.

Observations in the second interval have \eqn{2}{} entries that vary as a
linear function of their extraneous covariate. Let
\eqn{\beta = 1/2}{}. Then, the \eqn{(1, 2)/(2, 1)}{} positions for
the \eqn{i}{}-th observation in the second interval are
\eqn{\beta\cdot(1 - z_i)}{}, while the \eqn{(1, 3)/ (3, 1)}{}
entries are \eqn{\beta\cdot(1 + z_i)}{}.

Thus, as \eqn{z_i}{} approaches \eqn{-1}{} from the right, the associated
precision matrix becomes more similar to the matrix for observations in the
first interval. Similarly, as \eqn{z_i}{} approaches \eqn{1}{} from the left,
the matrix becomes more similar to the matrix for observations in the third
interval.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
library(ggplot2)

# get the data
set.seed(12)
data <- generateData()
X <- data$X
Z <- data$Z
interval <- data$interval
prec <- data$true_precision

# get overall and within interval sample sizes
n <- nrow(X)
n1 <- sum(interval == 1)
n2 <- sum(interval == 2)
n3 <- sum(interval == 3)

# visualize the distribution of the extraneous covariate
ggplot(data.frame(Z = Z, interval = as.factor(interval))) +
  geom_histogram(aes(Z, fill = interval), color = "black", bins = n %/% 5)

# visualize the true precision matrices in each of the intervals

# interval 1
matViz(prec[[1]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 1, observations 1,...,", n1))

# interval 2 (varies continuously with Z)
cat("\nInterval 2, observations ", n1 + 1, ",...,", n1 + n2, sep = "")
int2_mats <- prec[interval == 2]
int2_inds <- c(5, n2 %/% 2, n2 - 5)
lapply(int2_inds, function(j) matViz(int2_mats[[j]], incl_val = TRUE) +
         ggtitle(paste("True precision matrix, interval 2, observation", j + n1)))

# interval 3
matViz(prec[[length(prec)]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 3, observations ",
                 n1 + n2 + 1, ",...,", n1 + n2 + n3))

# fit the model and visualize the estimated graphs
(out <- covdepGE(X, Z))
plot(out)

# visualize the posterior inclusion probabilities for variables (1, 3) and (1, 2)
inclusionCurve(out, 1, 2)
inclusionCurve(out, 1, 3)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{inclusionCurve}{Plot PIP as a Function of Index}{inclusionCurve}
%
\begin{Description}\relax
Plot the posterior inclusion probability of an edge between two
variables as a function of observation index
\end{Description}
%
\begin{Usage}
\begin{verbatim}
inclusionCurve(
  out,
  col_idx1,
  col_idx2,
  line_type = "solid",
  line_size = 0.5,
  line_color = "black",
  point_shape = 21,
  point_size = 1.5,
  point_color = "#500000",
  point_fill = "white"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{out}] object of class \code{covdepGE}; return of \code{covdepGE} function

\item[\code{col\_idx1}] integer in \eqn{[1, p]}{}; column index of the first variable

\item[\code{col\_idx2}] integer in \eqn{[1, p]}{}; column index of the second variable

\item[\code{line\_type}] linetype; \code{ggplot2} line type to interpolate the
probabilities. \code{"solid"} by default

\item[\code{line\_size}] positive numeric; thickness of the interpolating line.
\code{0.5} by default

\item[\code{line\_color}] color; color of interpolating line. \code{"black"} by default

\item[\code{point\_shape}] shape; shape of the points denoting observation-specific
inclusion probabilities; \code{21} by default

\item[\code{point\_size}] positive numeric; size of probability points. \code{1.5} by
default

\item[\code{point\_color}] color; color of probability points. \code{"\#500000"} by default

\item[\code{point\_fill}] color; fill of probability points. Only applies to select
shapes. \code{"white"} by default
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns \code{ggplot2} visualization of inclusion probability curve
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
library(ggplot2)

# get the data
set.seed(12)
data <- generateData()
X <- data$X
Z <- data$Z
interval <- data$interval
prec <- data$true_precision

# get overall and within interval sample sizes
n <- nrow(X)
n1 <- sum(interval == 1)
n2 <- sum(interval == 2)
n3 <- sum(interval == 3)

# visualize the distribution of the extraneous covariate
ggplot(data.frame(Z = Z, interval = as.factor(interval))) +
  geom_histogram(aes(Z, fill = interval), color = "black", bins = n %/% 5)

# visualize the true precision matrices in each of the intervals

# interval 1
matViz(prec[[1]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 1, observations 1,...,", n1))

# interval 2 (varies continuously with Z)
cat("\nInterval 2, observations ", n1 + 1, ",...,", n1 + n2, sep = "")
int2_mats <- prec[interval == 2]
int2_inds <- c(5, n2 %/% 2, n2 - 5)
lapply(int2_inds, function(j) matViz(int2_mats[[j]], incl_val = TRUE) +
         ggtitle(paste("True precision matrix, interval 2, observation", j + n1)))

# interval 3
matViz(prec[[length(prec)]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 3, observations ",
                 n1 + n2 + 1, ",...,", n1 + n2 + n3))

# fit the model and visualize the estimated graphs
(out <- covdepGE(X, Z))
plot(out)

# visualize the posterior inclusion probabilities for variables (1, 3) and (1, 2)
inclusionCurve(out, 1, 2)
inclusionCurve(out, 1, 3)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{matViz}{Visualize a matrix}{matViz}
%
\begin{Description}\relax
Create a visualization of a matrix
\end{Description}
%
\begin{Usage}
\begin{verbatim}
matViz(
  x,
  color1 = "white",
  color2 = "#500000",
  grid_color = "black",
  incl_val = FALSE,
  prec = 2,
  font_size = 3,
  font_color1 = "black",
  font_color2 = "white",
  font_thres = mean(x)
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] matrix; matrix to be visualized

\item[\code{color1}] color; color for low entries. \code{"white"} by default

\item[\code{color2}] color; color for high entries. \code{"\#500000"} by default

\item[\code{grid\_color}] color; color of grid lines. \code{"black"} by default

\item[\code{incl\_val}] logical; if \code{TRUE}, the value for each entry will be
displayed. \code{FALSE} by default

\item[\code{prec}] positive integer; number of decimal places to round entries to if
\code{incl\_val} is \code{TRUE}. \code{2} by default

\item[\code{font\_size}] positive numeric; size of font if \code{incl\_val} is \code{TRUE}. \code{3}
by default

\item[\code{font\_color1}] color; color of font for low entries if \code{incl\_val} is
\code{TRUE}. \code{"black"} by default

\item[\code{font\_color2}] color; color of font for high entries if \code{incl\_val} is
\code{TRUE}. \code{"white"} by default

\item[\code{font\_thres}] numeric; values less than \code{font\_thres} will be displayed
in \code{font\_color1} if \code{incl\_val} is \code{TRUE}. \code{mean(x)} by default
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns \code{ggplot2} visualization of matrix
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
library(ggplot2)

# get the data
set.seed(12)
data <- generateData()
X <- data$X
Z <- data$Z
interval <- data$interval
prec <- data$true_precision

# get overall and within interval sample sizes
n <- nrow(X)
n1 <- sum(interval == 1)
n2 <- sum(interval == 2)
n3 <- sum(interval == 3)

# visualize the distribution of the extraneous covariate
ggplot(data.frame(Z = Z, interval = as.factor(interval))) +
  geom_histogram(aes(Z, fill = interval), color = "black", bins = n %/% 5)

# visualize the true precision matrices in each of the intervals

# interval 1
matViz(prec[[1]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 1, observations 1,...,", n1))

# interval 2 (varies continuously with Z)
cat("\nInterval 2, observations ", n1 + 1, ",...,", n1 + n2, sep = "")
int2_mats <- prec[interval == 2]
int2_inds <- c(5, n2 %/% 2, n2 - 5)
lapply(int2_inds, function(j) matViz(int2_mats[[j]], incl_val = TRUE) +
         ggtitle(paste("True precision matrix, interval 2, observation", j + n1)))

# interval 3
matViz(prec[[length(prec)]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 3, observations ",
                 n1 + n2 + 1, ",...,", n1 + n2 + n3))

# fit the model and visualize the estimated graphs
(out <- covdepGE(X, Z))
plot(out)

# visualize the posterior inclusion probabilities for variables (1, 3) and (1, 2)
inclusionCurve(out, 1, 2)
inclusionCurve(out, 1, 3)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.covdepGE}{Plot the Graphs Estimated by \code{covdepGE}}{plot.covdepGE}
%
\begin{Description}\relax
Create a list of the unique graphs estimated by \code{covdepGE}
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'covdepGE'
plot(x, graph_colors = NULL, title_sum = TRUE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] object of class \code{covdepGE}; return of \code{covdepGE} function

\item[\code{graph\_colors}] \code{NULL} OR vector; the \eqn{j}{}-th element is the color for
the \eqn{j}{}-th graph. If \code{NULL}, all graphs will be colored with \code{"\#500000"}.
\code{NULL} by default

\item[\code{title\_sum}] logical; if \code{TRUE} the indices of the observations
corresponding to the graph will be included in the title. \code{TRUE} by default

\item[\code{...}] additional arguments will be ignored
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns list of \code{ggplot2} visualizations of unique graphs estimated
by \code{covdepGE}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
library(ggplot2)

# get the data
set.seed(12)
data <- generateData()
X <- data$X
Z <- data$Z
interval <- data$interval
prec <- data$true_precision

# get overall and within interval sample sizes
n <- nrow(X)
n1 <- sum(interval == 1)
n2 <- sum(interval == 2)
n3 <- sum(interval == 3)

# visualize the distribution of the extraneous covariate
ggplot(data.frame(Z = Z, interval = as.factor(interval))) +
  geom_histogram(aes(Z, fill = interval), color = "black", bins = n %/% 5)

# visualize the true precision matrices in each of the intervals

# interval 1
matViz(prec[[1]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 1, observations 1,...,", n1))

# interval 2 (varies continuously with Z)
cat("\nInterval 2, observations ", n1 + 1, ",...,", n1 + n2, sep = "")
int2_mats <- prec[interval == 2]
int2_inds <- c(5, n2 %/% 2, n2 - 5)
lapply(int2_inds, function(j) matViz(int2_mats[[j]], incl_val = TRUE) +
         ggtitle(paste("True precision matrix, interval 2, observation", j + n1)))

# interval 3
matViz(prec[[length(prec)]], incl_val = TRUE) +
  ggtitle(paste0("True precision matrix, interval 3, observations ",
                 n1 + n2 + 1, ",...,", n1 + n2 + n3))

# fit the model and visualize the estimated graphs
(out <- covdepGE(X, Z))
plot(out)

# visualize the posterior inclusion probabilities for variables (1, 3) and (1, 2)
inclusionCurve(out, 1, 2)
inclusionCurve(out, 1, 3)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
