% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{covdepGE}
\alias{covdepGE}
\alias{covdepGE-method}
\title{covdepGE: Covariate Dependent Graph Estimation}
\usage{
covdepGE(
  data,
  Z,
  hp_method = "hybrid",
  ssq = NULL,
  sbsq = NULL,
  pip = NULL,
  nssq = 5,
  nsbsq = 5,
  npip = 5,
  ssq_mult = 1.5,
  ssq_lower = 1e-05,
  snr_upper = 25,
  sbsq_lower = 1e-05,
  pip_lower = 1e-05,
  pip_upper = NULL,
  tau = NULL,
  norm = 2,
  center_data = T,
  scale_Z = T,
  alpha_tol = 1e-10,
  max_iter_grid = 10,
  max_iter = 100,
  edge_threshold = 0.5,
  sym_method = "mean",
  parallel = F,
  num_workers = NULL,
  prog_bar = T
)
}
\arguments{
\item{data}{\verb{n x p numeric matrix}; data}

\item{Z}{\verb{n x q numeric matrix}; extraneous covariates}

\item{hp_method}{\code{character} in
\code{c("grid_search", "model_average", "hybrid")}; method for selecting
hyperparameters from the the hyperparameter grid. The grid will be generated
as the Cartesian product of \code{ssq}, \code{sbsq}, and \code{pip}. Fix the variable \code{y} as
the response; then, the hyperparameters will be selected as follows:

\itemize{
\item If \code{"grid_search"}, the point in the hyperparameter grid that
maximizes the total ELBO across all individuals will be selected
\item If \verb{"model_average}, then all posterior quantities will be a convex
combination of the variational estimates resulting from the model fit for
each point in the hyperparameter grid. Note that the weightings are
individual-specific, as unnormalized weights are calculated using the
exponentiated ELBO
\item If \code{"hybrid"}, then \code{pip} will be averaged over as with
\code{"model_average"}, while a single point in the grid defined by the
Cartesian product of \code{ssq} and \code{sbsq} will be selected via grid search for
each point in \code{pip}.
}

\code{"hybrid"} by default}

\item{ssq}{\code{NULL} OR \verb{numeric vector} with positive entries; candidate values
of the hyperparameter \code{sigma^2} (prior residual variance). If \code{NULL}, \code{ssq}
will be generated for each variable \code{y} fixed as the response as:\preformatted{ssq <- seq(ssq_lower, ssq_upper, length.out = nssq)
}

\code{NULL} by default}

\item{sbsq}{\code{NULL} OR \verb{numeric vector} with positive entries; candidate values
of the hyperparameter \verb{sigma^2_beta} (prior slab variance). If \code{NULL}, \code{sbsq}
will be generated for each variable \code{y} fixed as the response as:\preformatted{sbsq <- seq(sbsq_lower, sbsq_upper, length.out = nsbsq)
}

\code{NULL} by default}

\item{pip}{\code{NULL} OR \verb{numeric vector} with entries in \verb{(0, 1)}; candidate
values of the hyperparameter \code{pi} (prior inclusion probability). If \code{NULL},
\code{pip} will be generated for each variable \code{y} fixed as the response as:\preformatted{pip <- seq(pip_lower, pi_upper, length.out = npip)
}

\code{NULL} by default}

\item{nssq}{positive \code{integer}; number of points to generate for \code{ssq} if
\code{ssq} is \code{NULL}. \code{5} by default}

\item{nsbsq}{positive \code{integer}; number of points to generate for \code{sbsq} if
\code{sbsq} is \code{NULL}. \code{5} by default}

\item{npip}{positive \code{integer}; number of points to generate for \code{pip} if \code{pip}
is \code{NULL}. \code{5} by default}

\item{ssq_mult}{positive \code{numeric}; if \code{ssq} is \code{NULL}, then for each variable
\code{y} fixed as the response:\preformatted{ssq_upper <- ssq_mult * stats::var(y)
}

Then, \code{ssq_upper} will be the greatest value in \code{ssq} for variable \code{y}. \code{1.5}
by default}

\item{ssq_lower}{positive \code{numeric}; if \code{ssq} is \code{NULL}, then \code{ssq_lower}
will be the least value in \code{ssq}. \code{1e-5} by default}

\item{snr_upper}{positive \code{numeric}; upper bound on the signal to noise
ratio. If \code{sbsq} is \code{NULL}, then for each variable \code{y} fixed as the response:\preformatted{s2_sum <- sum(apply(X, 2, stats::var))
sbsq_upper <- snr_upper / (pip_upper * s2_sum)
}

Then, \code{sbsq_upper} will be the greatest value in \code{sbsq} for variable \code{y}.
\code{25} by default}

\item{sbsq_lower}{positive \code{numeric}; if \code{sbsq} is \code{NULL}, then \code{sbsq_lower}
will be the least value in \code{sbsq}. \code{1e-5} by default}

\item{pip_lower}{\code{numeric} in \verb{(0, 1)}; if \code{pip} is \code{NULL}, then
\code{pip_lower} will be the least value in \code{pip}. \code{1e-5} by default}

\item{pip_upper}{\code{NULL} OR  \code{numeric} in\verb{(0, 1)}; if \code{pip} is \code{NULL}, then
\code{pip_upper} will be the greatest value in \code{pip}. If \code{sbsq} is \code{NULL},
\code{pip_upper} will be used to calculate \code{sbsq_upper}. If \code{NULL}, \code{pip_upper}
will be calculated for each variable \code{y} fixed as the response as:\preformatted{lasso <- glmnet::cv.glmnet(X, y)
non0 <- sum(glmnet::coef.glmnet(lasso, s = "lambda.1se")[-1] != 0)
non0 <- min(max(non0, 1), p - 1)
pip_upper <- non0 / p
}

\code{NULL} by default}

\item{tau}{\code{NULL} OR positive \code{numeric} OR \verb{numeric vector} of length \code{n}
with positive entries; bandwidth parameter. Greater values allow for more
information to be shared between individuals. Allows for global or
individual-specific specification. If \code{NULL}, use 2-step KDE methodology as
described in (2) to calculate individual-specific bandwidths. \code{NULL} by
default}

\item{norm}{\code{numeric} in \verb{[1, Inf]}; norm to use when calculating weights.
\code{Inf} results in infinity norm. \code{2} by default}

\item{center_data}{\code{logical}; if \code{T}, center \code{data} column-wise to mean \code{0}.
\code{T} by default}

\item{scale_Z}{\code{logical}; if \code{T}, center and scale \code{Z} column-wise to mean \code{0},
standard deviation 1 prior to calculating the weights. \code{T} by default}

\item{alpha_tol}{positive \code{numeric}; end CAVI when the Frobenius norm of the
change in the alpha \code{matrix} is within \code{alpha_tol}. \code{1e-5} by default}

\item{max_iter_grid}{positive \code{integer}; if tolerance criteria has not been met
by \code{max_iter_grid} iterations during grid search, end CAVI. After grid search
has completed, CAVI is performed with the final hyperparameters selected by
grid search for at most \code{max_iter} iterations. Does not apply to
\code{hp_method = "model_average"}. \code{10} by default}

\item{max_iter}{positive \code{integer}; if tolerance criteria has not been met by
\code{max_iter} iterations, end CAVI. \code{100} by default}

\item{edge_threshold}{\code{numeric} in \verb{(0, 1)}; a graph for each individual
will be constructed by including an edge between variable \code{i} and
variable \code{j} if, and only if, the \verb{(i,j)} entry of the symmetrized
posterior inclusion probability \code{matrix} corresponding to the individual is
greater than \code{edge_threshold}. \code{0.5} by default}

\item{sym_method}{\code{character} in \verb{c("mean"}, \code{"max"}, \verb{"min")}; to symmetrize
the posterior inclusion probability \code{matrix} for each individual, the
\verb{(i,j)} and \verb{(j,i)} entries will be post-processed as
\verb{sym_method``((i,j) entry, (j,i) entry)}. \code{"mean"} by default}

\item{parallel}{\code{logical}; if \code{T}, hyperparameter selection and CAVI for each
of the \code{p} variables will be performed in parallel using \code{foreach}.
Parallel backend may be registered prior to making a call to \code{covdepGE}. If
no active parallel backend can be detected, then parallel backend will be
automatically registered using:\preformatted{doParallel::registerDoParallel(num_workers)
}}

\item{num_workers}{\code{NULL} OR positive \code{integer} less than or equal to
\code{parallel::detectCores()}; argument to \code{doParallel::registerDoParallel} if
\code{parallel = T} and no parallel backend is detected. If \code{NULL}, then:\preformatted{num_workers <- floor(parallel::detectCores() / 2)
}

\code{NULL} by default}

\item{prog_bar}{\code{logical}; if \code{T}, then a progress bar will be displayed
denoting the number of remaining variables to fix as the response and perform
CAVI. If \code{parallel}, no progress bar will be displayed. \code{T} by default}
}
\value{
Returns \code{list} with the following values:

\enumerate{

\item \code{graphs}: \code{list} with the following values:

\itemize{
\item \code{graphs}: \code{list} of \verb{n p x p numeric} matrices; the \code{l}-th
\code{matrix} is the adjacency \code{matrix} for the \code{l}-th individual
\item \code{unique_graphs}: \code{list}; the \code{l}-th element is a \code{list} containing
the \code{l}-th unique graph and the indices of the individual(s)
corresponding to this graph
\item \code{inclusion_probs_sym}: \code{list} of \verb{n p x p numeric} matrices; the
\code{l}-th \code{matrix} is the symmetrized posterior inclusion probability
\code{matrix} for the \code{l}-th individual
\item \code{inclusion_probs_asym}: \code{list} of \verb{n p x p numeric} matrices; the
\code{l}-th \code{matrix} is the posterior inclusion probability \code{matrix} for the
\code{l}-th individual prior to symmetrization
}

\item \code{variational_params}: \code{list} with the following values:

\itemize{
\item \code{alpha}: \code{list} of \verb{p n x (p - 1) numeric} matrices; the \verb{(i, j)}
entry of the \code{k}-th \code{matrix} is the variational approximation to the
posterior inclusion probability of the \code{j}-th variable in a weighted
regression with variable \code{k} fixed as the response, where the weights
are taken with respect to individual \code{i}
\item \code{mu}: \code{list} of \verb{p n x (p - 1) numeric} matrices; the \verb{(i, j)}
entry of the \code{k}-th \code{matrix} is the variational approximation to the
posterior slab mean for the \code{j}-th variable in a weighted regression
with variable \code{k} fixed as the response, where the weights are taken
with respect to individual \code{i}
\item \code{ssq_var}: \code{list} of \verb{p n x (p - 1) numeric} matrices; the
\verb{(i, j)} entry of the \code{k}-th \code{matrix} is the variational approximation
to the posterior slab variance for the \code{j}-th variable in a weighted
regression with variable \code{k} fixed as the response, where the weights
are taken with respect to individual \code{i}
}

\item \code{hyperparameters}: \code{list} of \code{p} lists; the \code{j}-th \code{list} has the
following values for variable \code{j} fixed as the response:

\itemize{
\item \code{grid}: \code{matrix} of candidate hyperparameter values, corresponding
ELBO, and iterations to converge
\item \code{final}: the final hyperparameters chosen by grid search, and the
ELBO and iterations to converge for these hyperparameters
}

\item \code{model_details}: \code{list} with the following values:

\itemize{
\item \code{elapsed}: amount of time to fit the model
\item \code{n}: number of individuals
\item \code{p}: number of variables
\item \code{ELBO}: ELBO summed across all individuals and variables. If
\code{hp_method} is \code{"model_average"} or \code{"hybrid"}, this ELBO is averaged
across the hyperparameter grid using the model averaging weights
\item \code{num_unique}: number of unique graphs
\item \code{grid_size}: number of points in the hyperparameter grid
\item \code{args}: \code{list} containing all passed arguments of \verb{length 1}
}

\item \code{weights}: \code{list} with the following values:

\itemize{
\item \code{weights}: \verb{n x n numeric matrix}. The \verb{(i, j)} entry is the weight
of the \code{i}-th individual with respect to the \code{j}-th individual using the
\code{j}-th individual's bandwidth
\item \code{bandwidths}: \verb{numeric vector} of length \code{n}. The \code{i}-th entry is
the bandwidth for the \code{i}-th individual
}
}
}
\description{
Model the conditional dependence structure of data as a function
of extraneous covariates as described in (1).
}
\examples{

library(ggplot2)

# get the data
set.seed(1)
data <- generateData()
X <- data$data
Z <- data$covts
interval <- data$interval
prec <- data$true_precision

# get overall and within interval sample sizes
n <- nrow(X)
n1 <- sum(interval == 1)
n2 <- sum(interval == 2)

# visualize the distribution of the extraneous covariate
ggplot(data.frame(Z = Z, interval = as.factor(interval))) +
geom_histogram(aes(Z, fill = interval), color = "black", bins = n \%/\% 5)

# visualize the true precision matrices in each of the intervals

# interval 1
matViz(prec[[1]], incl_val = TRUE) +
ggtitle("True precision matrix, interval 1")

# interval 2 (varies continuously with Z)
int2_mats <- prec[interval == 2]
int2_inds <- c(5, n2 \%/\% 2, n2 - 5)
lapply(int2_inds, function(j) matViz(int2_mats[[j]], incl_val = TRUE) +
ggtitle(paste("True precision matrix, interval 2, individual", j)))

# interval 3
matViz(prec[[length(prec)]], incl_val = TRUE) +
ggtitle("True precision matrix, interval 3")

# fit the model and visualize the estimated precision matrices
(out <- covdepGE(X, Z))
plot(out)

# visualize the inclusion probabilities for variables (1, 3) and (1, 2)
inclusionCurve(out, 1, 2)
inclusionCurve(out, 1, 3)
}
\references{
\enumerate{
\item Dasgupta S., Ghosh P., Pati D., Mallick B., \emph{An approximate Bayesian
approach to covariate dependent graphical modeling}, 2021
\item Dasgupta S., Pati D., Srivastava A., \emph{A Two-Step Geometric Framework For
Density Modeling}, Statistica Sinica, 2020
}
}
